{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPgcE8s5UHx7+G8ykmPmRuu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### **Ollama Installation**"],"metadata":{"id":"4OhnWxcsB2l_"}},{"cell_type":"code","source":["!sudo apt update\n","!sudo apt install -y pciutils\n","!curl -fsSL https://ollama.com/install.sh | sh"],"metadata":{"collapsed":true,"id":"skOl-AoMB-Y5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Run Ollama in background parallel**"],"metadata":{"id":"LyzgkxmUEF4x"}},{"cell_type":"code","source":["import threading\n","import subprocess\n","import time\n","\n","def run_ollama_serve():\n","  subprocess.Popen([\"ollama\",\"serve\"])\n","\n","thread=threading.Thread(target=run_ollama_serve)\n","thread.start()\n","time.sleep(5)"],"metadata":{"id":"IZJf2uEuEfSB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###**Installing Ollama**"],"metadata":{"id":"uosbx5DXFPDY"}},{"cell_type":"code","source":["!pip install ollama"],"metadata":{"collapsed":true,"id":"co7YNHOfFJHY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Pull Embedding Model**"],"metadata":{"id":"WX6obgRgGc54"}},{"cell_type":"code","source":["!ollama pull all-minilm"],"metadata":{"id":"fC0ykIQ4GnHD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Converting Text into Vector**"],"metadata":{"id":"LZGpqgppHb1h"}},{"cell_type":"code","source":["import ollama\n","#loads ollama library into program\n","\n","response=ollama.embeddings(\n","    model=\"all-minilm\",\n","    prompt=\"The sky is blue because of Rayleigh Scattering\"\n",")"],"metadata":{"id":"3St6VcNgFcl3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"id":"fCAHuC-CHWnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(response[\"embedding\"]))"],"metadata":{"id":"DkSSBLk1Hslr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The sentence converted into 384 dimensional vector"],"metadata":{"id":"pPO_PJ-qIQt-"}},{"cell_type":"markdown","source":["### **Vector Databases & Redis Chat Memory (with LangChain + Ollama Embeddings)**"],"metadata":{"id":"_2plXMVHRVDO"}},{"cell_type":"markdown","source":["**1.Install packages**"],"metadata":{"id":"sqI1ja1DiQfr"}},{"cell_type":"code","source":["!pip install langchain\n","#framework for use LLM and other model\n","!pip install langchain_community\n","#tool for using PDF loader, web base loader\n","!pip install langchain_core\n","#tool for use prompts,documents,runnable\n","!pip install langchain-redis\n","#LangChain uses Redis in a special way — as a memory store for conversations.\n","#It's like giving chatbot a brain that remembers previous chats,stored in redis\n","!pip install redis\n","#Redis is an open-source in-memory database\n","!pip install qdrant_client\n","!pip install pinecone-client"],"metadata":{"collapsed":true,"id":"CfAfSSUzRc9f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2.Import libraries**"],"metadata":{"id":"WVnyNVyqm0W-"}},{"cell_type":"code","source":["from langchain.text_splitter import CharacterTextSplitter\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain.document_loaders import TextLoader\n","from langchain_community.document_loaders import WebBaseLoader"],"metadata":{"id":"zOp0z7egm7jV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3.Load web document**"],"metadata":{"id":"HTIa8v7IohuA"}},{"cell_type":"code","source":["loader=WebBaseLoader(\"https://en.wikipedia.org/wiki/LangChain\")\n","document=loader.load()\n","print(document)"],"metadata":{"id":"noHB52Acoo7y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**4.Split the document**"],"metadata":{"id":"da0zv6wppJSZ"}},{"cell_type":"code","source":["splitter=RecursiveCharacterTextSplitter(\n","    chunk_size=500,\n","    chunk_overlap=0\n",")\n","chunk_document=splitter.split_documents(document)\n","print(chunk_document)"],"metadata":{"id":"q4T8kMikpO9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(chunk_document)"],"metadata":{"id":"HTP0fDi8qP51"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["chunk_document[:5]"],"metadata":{"id":"-hIvzE_CqSp-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **⚡ FAISS with Ollama Embeddings**"],"metadata":{"id":"FrXUtTXlrEnT"}},{"cell_type":"code","source":["#inatall faiss packages\n","!pip install faiss-cpu"],"metadata":{"id":"2cDRdM87rI3N","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import libraries both for faiss and ollama\n","from langchain_community.vectorstores import FAISS\n","from langchain.embeddings import OllamaEmbeddings"],"metadata":{"id":"4Pc8F8ACro86"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create an embedding model\n","embedding_model=OllamaEmbeddings(model=\"all-minilm\")"],"metadata":{"id":"cY7nHPdosRWg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#convert text into vector\n","vector_store=FAISS.from_documents(chunk_document,embedding_model)"],"metadata":{"id":"IvdboMgBsj2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save to disk\n","vector_store.save_local(\"faiss_index_of_chunk_document\")"],"metadata":{"id":"JXaK59DEtMGp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#load the document\n","load_document=FAISS.load_local(\n","    \"faiss_index_of_chunk_document\",\n","    embedding_model,\n","    allow_dangerous_deserialization=True)\n","\n","\n","#here embedding model is used to convert the user question into vector\n"],"metadata":{"id":"o7mhAPMitdMk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#metadata filtering\n","filtered_answer=load_document.similarity_search_with_score(\n","    \"What is langchain?\",\n","    k=3,\n","    filter={\n","        \"source\":[\"https://en.wikipedia.org/wiki/LangChain\"]\n","    }\n",")\n","\n","#here FAISS database store chunk as (page_content= .......,metadata= {source:...... }.......}.It represents a list of items so \"source\":\",.,.,.,.,.\"\n","#top 3 matches will be shown and the match which has less score will give priority"],"metadata":{"id":"q5zfBMwDw-d_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for doc, score in filtered_answer:\n","    print(\"Score:\", score)\n","    print(\"Content:\", doc.page_content)\n","    print(\"Source:\", doc.metadata.get(\"source\"))\n","    print(\"-\" * 100)"],"metadata":{"id":"hoFeJwPUyNcZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(filtered_answer)"],"metadata":{"id":"VpquVBdQxxRv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#without metadata filtering\n","load_document.similarity_search(\n","    \"What is langchain?\",\n","    k=2\n",")"],"metadata":{"id":"GkU2loGoz_xm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## `**Hybrid Search ((FAISS + Ollama Embedding)(Semantic Search) + Keyword Search(lexical Search)) **`"],"metadata":{"id":"9vGdNYr_0_cC"}},{"cell_type":"markdown","source":["**BM25 (Best Matching 25) is a ranking algorithm used to find the most relevant documents based on a user's query — especially in keyword-based search systems like search engines.**"],"metadata":{"id":"Mvg0I2Y22ACd"}},{"cell_type":"markdown","source":["### **BM25 Setup**"],"metadata":{"id":"F0VOGkk3MGSU"}},{"cell_type":"code","source":["#install packages\n","!pip install rank_bm25"],"metadata":{"id":"ud-KHNV81mWT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import libraries\n","from rank_bm25 import BM25Okapi"],"metadata":{"id":"uOMV5Iv14vGG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#BM25 setup\n","\n","#1.load page_content from document,extracts only page_content without metadata\n","texts=[]\n","for doc in chunk_document:\n","  text=doc.page_content #get the page content from real document\n","  texts.append(text)\n","\n","#2.spilt the text of th document,converts raw text into tokens\n","tokenized_text=[]\n","for token in texts:\n","  token_text=token.split(\" \")\n","  tokenized_text.append(token_text)\n","\n","#3.build an index and calculate how relevant each document is to a query.\n","bm25=BM25Okapi(tokenized_text)"],"metadata":{"id":"T9XoH6OI466F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#testing\n","query=\"what is langchain?\"\n","tokenized_query=query.split(\" \")\n","bm25_scroes=bm25.get_scores(tokenized_query)\n","print(\"Scroes : \", bm25_scroes)"],"metadata":{"id":"i197Icz9LBN9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find and return the top N most relevant documents based on the BM25 similarity score between your user’s query and the stored document chunks.\n","\n","# 1. Setting top document\n","top_n=2\n","\n","# 2.  Pair each score with its corresponding index\n","## Example: [(0, 0.0), (1, 0.5), (2, 2.1), (3, 0.0), (4, 3.0), ...]\n","#>>(index,scores)\n","indexed_scores=list(enumerate(bm25_scroes))\n","\n","#3.sorting indexed scores based on scores..\n","#item[1] iterate the second item cause score is the second item\n","sorted_indexed_scores=sorted(\n","    indexed_scores,\n","    key=lambda item : item[1],\n","    reverse=True )\n","\n","#4. Select the top N scored documents\n","top_documents=sorted_indexed_scores[:top_n]\n","\n","#5. Now get the document by indecies\n","bm25_document=[]\n","for index,score in top_documents:\n","  doc_index=chunk_document[index]\n","  bm25_document.append(doc_index)\n"],"metadata":{"id":"-z3lIE9uOYZS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["faiss_database=vector_store.similarity_search(query,k=2)"],"metadata":{"id":"7vBv1JA4TvhM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#combine faiss db and bm25 (hybrid search)\n","\n","all_document=faiss_database+bm25_document\n","unique_docs_dict = {}\n","for doc in all_document:\n","    unique_docs_dict[doc.page_content] = doc\n","\n","combined_docs = list(unique_docs_dict.values())"],"metadata":{"id":"ZHFVXklkUWwB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(combined_docs)"],"metadata":{"id":"Rfm454J7VI8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["combined_docs"],"metadata":{"id":"bbGJ92B2VhPH"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bdcadce3"},"source":["!pip install langchain_community"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **ChromaDB**"],"metadata":{"id":"Qm6FQmNJELE7"}},{"cell_type":"code","source":["#install packages\n","!pip install chromadb"],"metadata":{"collapsed":true,"id":"6uxwsG0BEUk0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#import libraries\n","from langchain_community.vectorstores import Chroma"],"metadata":{"id":"nO5EJdxyJVTq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create an embedding model\n","embedding_model=OllamaEmbeddings(model=\"all-minilm\")"],"metadata":{"id":"B_zQdEYAJuw3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#chunk_document\n","chunk_document"],"metadata":{"collapsed":true,"id":"y97rMC7rKCU8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create a vector store to convert text into vector and save it into a database\n","vector_store_chroma=Chroma.from_documents(\n","    chunk_document,\n","    embedding_model,\n","    persist_directory=\"chroma_store\" #save to local disk\n",")"],"metadata":{"id":"txUazJKeKGpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Add new document to chroma_store\n","vector_store_chroma.add_texts([\"Another Document\"],metadatas=[{\"source\":\"Manual\"}])"],"metadata":{"id":"U07QtOOdKq57"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Chroma uses this ID to keep track of document.This ID can be used later to delete or update that specific document.basically, it's like a document name created automatically by Chroma."],"metadata":{"id":"cGgEgSzaMUOm"}},{"cell_type":"code","source":["#similarity search\n","vector_store_chroma.similarity_search(\"What is langchain?\",k=2)"],"metadata":{"id":"pnnAaGz2NZqr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#get the details about an document\n","vector_store_chroma.get(\"c672ec27-d1a5-453f-8f0e-08a1a46dd768\")"],"metadata":{"id":"TFSpM8pxN5K3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Access the chroma database collection\n","chroma_collection=vector_store_chroma._collection"],"metadata":{"id":"4hstPjLtOJn5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(chroma_collection)"],"metadata":{"id":"3UwRKhdeOcMN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get all IDs of vector_store_chroma database\n","all_chroma_collection_ids=chroma_collection.get()\n","\n","print(\"All ChromaDB Document IDs:\",all_chroma_collection_ids)"],"metadata":{"id":"g8SiUj8LOe31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get all IDs of vector_store_chroma database\n","all_chroma_collection_ids=chroma_collection.get(include=[])\n","\n","print(\"All ChromaDB Document IDs:\",all_chroma_collection_ids)"],"metadata":{"id":"eDEJXJ6PPMuZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Get all IDs of vector_store_chroma database\n","all_chroma_collection_ids=chroma_collection.get(include=[])['ids']\n","\n","print(\"All ChromaDB Document IDs:\",all_chroma_collection_ids)"],"metadata":{"id":"BBlw5aQvPSC1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#delete one item\n","vector_store_chroma.delete(ids=[\"2a390620-4633-427e-abe8-2dc61d31b179\"])"],"metadata":{"id":"vi2OlstWPbjB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_chroma_collection_ids=chroma_collection.get(include=[])['ids']\n","\n","print(\"All ChromaDB Document IDs:\",all_chroma_collection_ids)"],"metadata":{"id":"DZx6mYIbP9RB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector_store_chroma.get(\"2a390620-4633-427e-abe8-2dc61d31b179\")"],"metadata":{"id":"JsTIpw_3QJdT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#metadata filtering\n","filtered_result=vector_store_chroma.similarity_search(\n","    \"what is langchain?\",\n","    k=2,\n","    filter={\n","        \"source\": \"https://en.wikipedia.org/wiki/LangChain\"\n","    }\n",")\n","print(filtered_result)"],"metadata":{"id":"y00qlHoBQPTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Hybrid Search\n","#1.Extract only the page_content from document\n","texts=[]\n","for doc in chunk_document:\n","  text=doc.page_content\n","  texts.append(text)\n","\n","print(texts)"],"metadata":{"id":"OdPWxy3iRyKY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#2.Tokenize the text\n","tokenized_text=[]\n","for doc in texts:\n","  token=doc.split(\" \")\n","  tokenized_text.append(token)\n","\n","print(tokenized_text)"],"metadata":{"id":"vnKf63D1SICL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#3.bm25 for hybrid search\n","bm25=BM25Okapi(tokenized_text)\n","print(bm25)"],"metadata":{"id":"D2cxM4uUTFwE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["It's showing the memory address of the object"],"metadata":{"id":"DYuBEuwsTjKB"}},{"cell_type":"code","source":["#testing\n","query=\"What is langchain\"\n","\n","#split the query\n","splited_query=query.split(\" \")\n","print(\"Splitted Query:\",splited_query)\n","\n","#get bm25 scores\n","bm25_scores=bm25.get_scores(splited_query)\n","print(\"BM25 Scores:\",bm25_scores)"],"metadata":{"id":"YurBfSP7Tj05"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#get bm25 searched document rank\n","bm25_rank=enumerate(bm25_scores)\n","print(bm25_rank)\n","bm25_rank=sorted(enumerate(bm25_scores))\n","print(bm25_rank)\n","bm25_rank=sorted(enumerate(bm25_scores),key= lambda x:x[1])\n","print(bm25_rank)\n","bm25_ranks=sorted(enumerate(bm25_scores), key=lambda x:x[1],reverse=True)\n","print(bm25_ranks)\n"],"metadata":{"id":"-pOdJfRBWsHO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#print the top 2 document\n","top_documents_choroma=bm25_ranks[:2]\n","print(top_documents)"],"metadata":{"id":"51PcGut4W9TR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#content of the top2 document\n","bm25_chroma_document=[]\n","for index,score in top_documents:\n","  document_index=chunk_document[index]\n","  bm25_chroma_document.append(document_index)\n","\n","print(bm25_chroma_document)"],"metadata":{"id":"AG1hX0T4ZKs6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#create semantic seached document\n","semantic_document_chroma=vector_store_chroma.similarity_search(query,k=5)"],"metadata":{"id":"xucoEVKvaaWL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Combining semantic and keyword based search\n","\n","all_documents_chroma=semantic_document_chroma+bm25_chroma_document\n","print(all_documents_chroma)"],"metadata":{"id":"9HP7BOf4bUJh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hybrid_search_chroma_dict={}\n","for doc in all_documents_chroma:\n","  hybrid_search_chroma_dict[doc.page_content]=doc\n","  print(doc)\n","\n","\n","print(\"+\"*100)\n","print(hybrid_search_chroma_dict)"],"metadata":{"id":"Jpcj3JOfcNqL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hybrid_documet_chroma=list(hybrid_search_chroma_dict.values())\n","print(hybrid_documet_chroma)"],"metadata":{"id":"vugAf1FLdACW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hybrid_documet_chroma"],"metadata":{"id":"ei7FsXzYfTq9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lAv5opFifV23"},"execution_count":null,"outputs":[]}]}